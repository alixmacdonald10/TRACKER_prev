{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "TRACKER-PreProcessing-Denoising.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNIf3+jaSmjqe2+9d2QXpP0",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ac7ff71826e340e3bad33ba4276d6c71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5a2568aefb9a47e5a3b631d53254b85e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ea916194a6ec474e9843c973126e9127",
              "IPY_MODEL_26608bdcbf9a445c8f0c7d250a87c827",
              "IPY_MODEL_717d805684e4431fba435aba5744883c"
            ]
          }
        },
        "5a2568aefb9a47e5a3b631d53254b85e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ea916194a6ec474e9843c973126e9127": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_03ed9f7cea9a4aa38cdfd7e28b4f8535",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 40%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_028d1bd0478049b7b67f3101cc5dda3d"
          }
        },
        "26608bdcbf9a445c8f0c7d250a87c827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfb74b1388ee4b17989c7c19f3df9054",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 5,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9b042f5a74b24a1399fb9fe51cdb2721"
          }
        },
        "717d805684e4431fba435aba5744883c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_78882d6a148a4d50b0bbca8f5483b4c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/5 [09:32&lt;14:08, 282.76s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fb1038999bfb46bdb1688a7aa1931b10"
          }
        },
        "03ed9f7cea9a4aa38cdfd7e28b4f8535": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "028d1bd0478049b7b67f3101cc5dda3d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfb74b1388ee4b17989c7c19f3df9054": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9b042f5a74b24a1399fb9fe51cdb2721": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "78882d6a148a4d50b0bbca8f5483b4c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fb1038999bfb46bdb1688a7aa1931b10": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee3fd3b9197643ebbb3ba80821d1a969": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5ab3eae616a4432d9c3d256fb95b4114",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_abcd894f10844a2e9c4912daaf87d10e",
              "IPY_MODEL_1b0c934cde694723a6a55b5d6243ad59",
              "IPY_MODEL_ec808e7566154ef1986bd4322639b5de"
            ]
          }
        },
        "5ab3eae616a4432d9c3d256fb95b4114": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "abcd894f10844a2e9c4912daaf87d10e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3d694af831974521bb5e1a6b3009e5b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9f4890e538a04a2b91971f6d2c8c4643"
          }
        },
        "1b0c934cde694723a6a55b5d6243ad59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dffff040b01e4345a0cd96c0956c3721",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b7262cddab9c4dc4b4d8a1c23135f8f3"
          }
        },
        "ec808e7566154ef1986bd4322639b5de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f259b8261e914d7eab37239aa26393c2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [04:30&lt;00:00, 14.71s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1876d6137793414abc93ce6133193000"
          }
        },
        "3d694af831974521bb5e1a6b3009e5b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9f4890e538a04a2b91971f6d2c8c4643": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dffff040b01e4345a0cd96c0956c3721": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b7262cddab9c4dc4b4d8a1c23135f8f3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f259b8261e914d7eab37239aa26393c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1876d6137793414abc93ce6133193000": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "88286ff290e240b2ae0c3e7f0f09bdb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f6a60537223f49c28f519d805c976d82",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_c68df2fbe94b4a459e51795104373853",
              "IPY_MODEL_685a1360820d4d3caafcad7d5f27e1b1",
              "IPY_MODEL_c9687f3e7f4c4385a3cdb36f4ddb222a"
            ]
          }
        },
        "f6a60537223f49c28f519d805c976d82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c68df2fbe94b4a459e51795104373853": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d291d298a369495985215bea2b1c814c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1c25879b45024aee946f50f9ebb32060"
          }
        },
        "685a1360820d4d3caafcad7d5f27e1b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6ee72ae0481d48b9ae704ed79a98c0e2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7446320cb6084451b8ca37dea834fef5"
          }
        },
        "c9687f3e7f4c4385a3cdb36f4ddb222a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc3f930b5cc0462eb5546bf057a487ae",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:35&lt;00:00, 16.97s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2473f3607714410eb29c5d6a7ea97e40"
          }
        },
        "d291d298a369495985215bea2b1c814c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1c25879b45024aee946f50f9ebb32060": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6ee72ae0481d48b9ae704ed79a98c0e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7446320cb6084451b8ca37dea834fef5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc3f930b5cc0462eb5546bf057a487ae": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2473f3607714410eb29c5d6a7ea97e40": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ee5725f6f0424bd3b37a726ce4c9c4b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_372048ff681b4ad78de7164109edfce6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_80a345217cce4f9ea0ca33fbd4396675",
              "IPY_MODEL_4930b9a170ed44d98b7fca79f8c90e3c",
              "IPY_MODEL_2e1123d569564cb3a4dd8df5d063bfb6"
            ]
          }
        },
        "372048ff681b4ad78de7164109edfce6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "80a345217cce4f9ea0ca33fbd4396675": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_485f368e07944635aca1e4c71ac84820",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_582a09011a1a44f0919c3f7dea4aa48a"
          }
        },
        "4930b9a170ed44d98b7fca79f8c90e3c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_54c441220449465b9f4315b1544e2531",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 16,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19bc31f2ad6a4d1497ff67bec5e1ddee"
          }
        },
        "2e1123d569564cb3a4dd8df5d063bfb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0b2388ad49ad405b94c5447dce695042",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 16/16 [03:52&lt;00:00, 13.64s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d338e7386285454b993cb2640d2017b2"
          }
        },
        "485f368e07944635aca1e4c71ac84820": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "582a09011a1a44f0919c3f7dea4aa48a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "54c441220449465b9f4315b1544e2531": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19bc31f2ad6a4d1497ff67bec5e1ddee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0b2388ad49ad405b94c5447dce695042": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d338e7386285454b993cb2640d2017b2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ccd9d724f41140cbacb93b36f598093d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_201277330fad40fbb02552308eb7b30f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f9a025f52864201ab439d8d0e6ad622",
              "IPY_MODEL_d862ff7989f447d39d63090e4a1c2584",
              "IPY_MODEL_5fef4567c5634bfabca3e627e21e8bba"
            ]
          }
        },
        "201277330fad40fbb02552308eb7b30f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f9a025f52864201ab439d8d0e6ad622": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0ec357ee46614714b47f116fcf7f1a72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d93a512307ce491ca857e6b73dc57c2a"
          }
        },
        "d862ff7989f447d39d63090e4a1c2584": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cf96689cb9fe4f8eb7ede80246108e49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73620cc654d241d9adb0d24948c5ae8d"
          }
        },
        "5fef4567c5634bfabca3e627e21e8bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_020b410d16ab4478ad4bb659dcdc4afc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:34&lt;00:00, 16.26s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_149bde90a5db4c868e30a51f6fc91939"
          }
        },
        "0ec357ee46614714b47f116fcf7f1a72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d93a512307ce491ca857e6b73dc57c2a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cf96689cb9fe4f8eb7ede80246108e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73620cc654d241d9adb0d24948c5ae8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "020b410d16ab4478ad4bb659dcdc4afc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "149bde90a5db4c868e30a51f6fc91939": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dee27a23d88a481e85151969d0009cc8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ac8568ac7bf040d1ac938674c7c588fb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4306301c9b874fe7ab6c6fe0dae31c90",
              "IPY_MODEL_3f2dc8fe70f34539be3d3125fd4026dd",
              "IPY_MODEL_7d5cab5d05a6472a9771623149fafb7c"
            ]
          }
        },
        "ac8568ac7bf040d1ac938674c7c588fb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4306301c9b874fe7ab6c6fe0dae31c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7b70ca1aae3848e0899f445bc6bf14ca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 38%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_73aaeff9c09c48a185f581de35e5f18a"
          }
        },
        "3f2dc8fe70f34539be3d3125fd4026dd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_45b6f69e3ab24ab7878d7b4cd34512fb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 16,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 6,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5f4d91546879432c8e3d5074415a013b"
          }
        },
        "7d5cab5d05a6472a9771623149fafb7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b675fe8e926d4744a4b98142b7b313a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 6/16 [01:32&lt;02:20, 14.08s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f3894c303e64f8f8721761526f25b60"
          }
        },
        "7b70ca1aae3848e0899f445bc6bf14ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "73aaeff9c09c48a185f581de35e5f18a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "45b6f69e3ab24ab7878d7b4cd34512fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5f4d91546879432c8e3d5074415a013b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b675fe8e926d4744a4b98142b7b313a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f3894c303e64f8f8721761526f25b60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/alixmacdonald10/TRACKER/blob/main/TRACKER_PreProcessing_Denoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Odvung2WoAG7"
      },
      "source": [
        "#PREREQUISITS"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HvjdqiSYWK_b"
      },
      "source": [
        "##Mount drive\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gKSt4uB5Hyqf",
        "outputId": "4080da08-112c-4f3f-9505-9d9e14bf0892"
      },
      "source": [
        "from google.colab import drive\n",
        " \n",
        "# mount drive to access file\n",
        "drive.mount('/content/gdrive')\n",
        "root_path = 'gdrive/My Drive/your_project_folder/'  #change dir to your project folder"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y7wVpTTyoQp_"
      },
      "source": [
        "##Install requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "stNoG62OsN2T",
        "outputId": "c1216ebf-9d93-4e12-b8e0-65c66b6b87d1"
      },
      "source": [
        "# install weights and bias for logging\n",
        "!pip install wandb -qqq\n",
        "import wandb\n",
        "\n",
        "wandb.login()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mamackerel\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zD6qFaOcHabQ",
        "outputId": "8e46292e-28ab-42b9-8bd3-2f3d16fef27b"
      },
      "source": [
        "# NN imports\n",
        "!pip3 install torch==1.9.0+cu102 torchvision==0.10.0+cu102 torchaudio===0.9.0 -f https://download.pytorch.org/whl/torch_stable.html\n",
        "!pip install tensorboard"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Requirement already satisfied: torch==1.9.0+cu102 in /usr/local/lib/python3.7/dist-packages (1.9.0+cu102)\n",
            "Requirement already satisfied: torchvision==0.10.0+cu102 in /usr/local/lib/python3.7/dist-packages (0.10.0+cu102)\n",
            "Requirement already satisfied: torchaudio===0.9.0 in /usr/local/lib/python3.7/dist-packages (0.9.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.9.0+cu102) (3.7.4.3)\n",
            "Requirement already satisfied: pillow>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision==0.10.0+cu102) (1.19.5)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (2.6.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (57.4.0)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.17.3)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.35.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (2.23.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.4.6)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.37.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (3.3.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.12.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.19.5)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.0.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.8.0)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard) (1.41.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard) (2021.5.30)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard) (3.7.4.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpVmyQVndxRl",
        "outputId": "41de4ecc-0db1-4f44-aee9-8597ffcce916"
      },
      "source": [
        "# database specific imports\n",
        "!pip3 install h5py"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (3.1.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.14.5 in /usr/local/lib/python3.7/dist-packages (from h5py) (1.19.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hf4Gre85krt6"
      },
      "source": [
        "##Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7t7mUj8SA2R"
      },
      "source": [
        "%load_ext tensorboard\n",
        "import torch\n",
        "from torch.utils import data\n",
        "from torchvision import transforms\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "import torch.nn as nn\n",
        "from torch import optim\n",
        "from torch.optim import lr_scheduler\n",
        "\n",
        "import h5py\n",
        "import numpy as np\n",
        "from pathlib import Path\n",
        "import random\n",
        "import time\n",
        "import copy\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from google.colab.patches import cv2_imshow"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxDHfKBW50hY"
      },
      "source": [
        "##Check Cuda"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N7QlP9Eb7fyt",
        "outputId": "9cffa00e-e694-4d60-aebb-4b968081cf6c"
      },
      "source": [
        "# Check devices\n",
        "num_devices = torch.cuda.device_count()\n",
        "print(f'Number of cuda devices: {num_devices}')\n",
        "for device in range(0, num_devices):\n",
        "  device_name = torch.cuda.get_device_name(device)\n",
        "  print(f'Cuda device name: {device_name}')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of cuda devices: 1\n",
            "Cuda device name: Tesla P100-PCIE-16GB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYIWYgu6oemA"
      },
      "source": [
        "#MODEL INFORMATION"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DpgflIdcqHby"
      },
      "source": [
        "##Set hyper parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rBGZ7StmqJCZ"
      },
      "source": [
        "# define hyper parameters\n",
        "project_name = 'Tracker-PreProcessing-Denoising'\n",
        "verbose = 1  # print out helpers\n",
        "transformed_when = 'after patches'\n",
        "transform1 = 'hflip'\n",
        "transform2 = 'rotate'\n",
        "patch_size = 256\n",
        "patch_stride = (12 * patch_size)\n",
        "plot_itterations = 1\n",
        "num_epoch = 5\n",
        "max_itterations = 4e5\n",
        "initial_learning_rate = 2e-4\n",
        "min_learning_rate = 1e-7\n",
        "loss_type = \"PSNR\"\n",
        "scheduler_type = \"cosine_annealing\"\n",
        "optimizer_type = \"Adam\"\n",
        "if optimizer_type == \"SGD\":\n",
        "  batch = 1\n",
        "else:\n",
        "  batch = 8  #  max batch size for cuda memory\n",
        "mini_batch_size = 4\n",
        "fpath = '/content/gdrive/MyDrive/Programming/datasets/noisyDataset.hdf5'"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGCjD-JAvzW4"
      },
      "source": [
        "# Track hyperparameters and run metadata\n",
        "hyperparameters = {\n",
        "  \"device_name\": device_name,\n",
        "  \"transformed_when\": transformed_when,\n",
        "  \"transform1\": transform1,\n",
        "  \"transform2\": transform2,\n",
        "  \"verbose\": verbose,\n",
        "  \"patch_size\": patch_size,\n",
        "  \"patch_stride\": patch_stride,\n",
        "  \"plot_itterations\": plot_itterations,\n",
        "  \"batch\": batch,\n",
        "  \"mini_batch_size\": mini_batch_size,\n",
        "  \"num_epoch\": num_epoch,\n",
        "  \"max_itterations\": max_itterations,\n",
        "  \"initial_learning_rate\": initial_learning_rate,\n",
        "  \"min_learning_rate\": min_learning_rate,\n",
        "  \"scheduler_type\": scheduler_type,\n",
        "  \"loss_type\": \"PSNR\",\n",
        "  \"optimizer_type\": optimizer_type,\n",
        "  \"architecture\": \"HINet\",\n",
        "  \"dataset\": \"Smartphone Image Denoising Dataset (SIDD)\",\n",
        "  \"project_name\": project_name\n",
        "}"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYXbowqpWVMB"
      },
      "source": [
        "##Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kvDOKrIDzX0S"
      },
      "source": [
        "###Note for transfer learning and importing pre-trained models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CZ94AmjzzWjc",
        "outputId": "c78bac0b-fa24-4c32-86a7-292184862949"
      },
      "source": [
        "''' \n",
        "Models can be imported from saved files and transfer learned by:\n",
        " \n",
        "'''\n",
        "#from torchvision import models\n",
        " \n",
        "#model = models.resnet101(pretrained=True)\n",
        " \n",
        "# TO ONLY TRAIN THE LAST LAYER (TRANSFER LEARNING) DO THE FOLLOWING\n",
        "#for param in model.parameters():\n",
        "#   param.requires_grad = False  # freezes all layers in beginning\n",
        " \n",
        "# return number of features in output (to transfer learn)\n",
        "#num_ftrs = model.fc.in_features\n",
        " \n",
        "# set output fully connected using\n",
        "#model.fc = nn.Linear(num_ftrs, 2)   # (input layers, output layers)\n",
        "#model.to(device)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "' \\nModels can be imported from saved files and transfer learned by:\\n \\n'"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhaJ-ruRpKHQ"
      },
      "source": [
        "###Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cu7d0oiR2WcU"
      },
      "source": [
        "'''\n",
        "HINet: Half Instance Normalization Network for Image Restoration\n",
        "@inproceedings{chen2021hinet,\n",
        "  title={HINet: Half Instance Normalization Network for Image Restoration},\n",
        "  author={Liangyu Chen and Xin Lu and Jie Zhang and Xiaojie Chu and Chengpeng Chen},\n",
        "  booktitle={IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops},\n",
        "  year={2021}\n",
        "}\n",
        "'''\n",
        "\n",
        "\n",
        "def conv3x3(in_chn, out_chn, bias=True):\n",
        "    layer = nn.Conv2d(in_chn, out_chn, kernel_size=3, stride=1, padding=1, bias=bias)\n",
        "    return layer\n",
        "\n",
        "def conv_down(in_chn, out_chn, bias=False):\n",
        "    layer = nn.Conv2d(in_chn, out_chn, kernel_size=4, stride=2, padding=1, bias=bias)\n",
        "    return layer\n",
        "\n",
        "def conv(in_channels, out_channels, kernel_size, bias=False, stride = 1):\n",
        "    return nn.Conv2d(\n",
        "        in_channels, out_channels, kernel_size,\n",
        "        padding=(kernel_size//2), bias=bias, stride = stride)\n",
        "\n",
        "## Supervised Attention Module\n",
        "class SAM(nn.Module):\n",
        "    def __init__(self, n_feat, kernel_size=3, bias=True):\n",
        "        super(SAM, self).__init__()\n",
        "        self.conv1 = conv(n_feat, n_feat, kernel_size, bias=bias)\n",
        "        self.conv2 = conv(n_feat, 3, kernel_size, bias=bias)\n",
        "        self.conv3 = conv(3, n_feat, kernel_size, bias=bias)\n",
        "\n",
        "    def forward(self, x, x_img):\n",
        "        x1 = self.conv1(x)\n",
        "        img = self.conv2(x) + x_img\n",
        "        x2 = torch.sigmoid(self.conv3(img))\n",
        "        x1 = x1*x2\n",
        "        x1 = x1+x\n",
        "        return x1, img\n",
        "\n",
        "class HINet(nn.Module):\n",
        "\n",
        "    def __init__(self, in_chn=3, wf=64, depth=5, relu_slope=0.2, hin_position_left=0, hin_position_right=4):\n",
        "        super(HINet, self).__init__()\n",
        "        self.depth = depth\n",
        "        self.down_path_1 = nn.ModuleList()\n",
        "        self.down_path_2 = nn.ModuleList()\n",
        "        self.conv_01 = nn.Conv2d(in_chn, wf, 3, 1, 1)\n",
        "        self.conv_02 = nn.Conv2d(in_chn, wf, 3, 1, 1)\n",
        "\n",
        "        prev_channels = self.get_input_chn(wf)\n",
        "        for i in range(depth): #0,1,2,3,4\n",
        "            use_HIN = True if hin_position_left <= i and i <= hin_position_right else False\n",
        "            downsample = True if (i+1) < depth else False\n",
        "            self.down_path_1.append(UNetConvBlock(prev_channels, (2**i) * wf, downsample, relu_slope, use_HIN=use_HIN))\n",
        "            self.down_path_2.append(UNetConvBlock(prev_channels, (2**i) * wf, downsample, relu_slope, use_csff=downsample, use_HIN=use_HIN))\n",
        "            prev_channels = (2**i) * wf\n",
        "\n",
        "        self.up_path_1 = nn.ModuleList()\n",
        "        self.up_path_2 = nn.ModuleList()\n",
        "        self.skip_conv_1 = nn.ModuleList()\n",
        "        self.skip_conv_2 = nn.ModuleList()\n",
        "        for i in reversed(range(depth - 1)):\n",
        "            self.up_path_1.append(UNetUpBlock(prev_channels, (2**i)*wf, relu_slope))\n",
        "            self.up_path_2.append(UNetUpBlock(prev_channels, (2**i)*wf, relu_slope))\n",
        "            self.skip_conv_1.append(nn.Conv2d((2**i)*wf, (2**i)*wf, 3, 1, 1))\n",
        "            self.skip_conv_2.append(nn.Conv2d((2**i)*wf, (2**i)*wf, 3, 1, 1))\n",
        "            prev_channels = (2**i)*wf\n",
        "        self.sam12 = SAM(prev_channels)\n",
        "        self.cat12 = nn.Conv2d(prev_channels*2, prev_channels, 1, 1, 0)\n",
        "\n",
        "        self.last = conv3x3(prev_channels, in_chn, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        image = x\n",
        "        #stage 1\n",
        "        x1 = self.conv_01(image)\n",
        "        encs = []\n",
        "        decs = []\n",
        "        for i, down in enumerate(self.down_path_1):\n",
        "            if (i+1) < self.depth:\n",
        "                x1, x1_up = down(x1)\n",
        "                encs.append(x1_up)\n",
        "            else:\n",
        "                x1 = down(x1)\n",
        "\n",
        "        for i, up in enumerate(self.up_path_1):\n",
        "            x1 = up(x1, self.skip_conv_1[i](encs[-i-1]))\n",
        "            decs.append(x1)\n",
        "\n",
        "        sam_feature, out_1 = self.sam12(x1, image)\n",
        "        #stage 2\n",
        "        x2 = self.conv_02(image)\n",
        "        x2 = self.cat12(torch.cat([x2, sam_feature], dim=1))\n",
        "        blocks = []\n",
        "        for i, down in enumerate(self.down_path_2):\n",
        "            if (i+1) < self.depth:\n",
        "                x2, x2_up = down(x2, encs[i], decs[-i-1])\n",
        "                blocks.append(x2_up)\n",
        "            else:\n",
        "                x2 = down(x2)\n",
        "\n",
        "        for i, up in enumerate(self.up_path_2):\n",
        "            x2 = up(x2, self.skip_conv_2[i](blocks[-i-1]))\n",
        "\n",
        "        out_2 = self.last(x2)\n",
        "        out_2 = out_2 + image\n",
        "        return [out_1, out_2]\n",
        "\n",
        "    def get_input_chn(self, in_chn):\n",
        "        return in_chn\n",
        "\n",
        "    def _initialize(self):\n",
        "        gain = nn.init.calculate_gain('leaky_relu', 0.20)\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.orthogonal_(m.weight, gain=gain)\n",
        "                if not m.bias is None:\n",
        "                    nn.init.constant_(m.bias, 0)\n",
        "\n",
        "\n",
        "class UNetConvBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, downsample, relu_slope, use_csff=False, use_HIN=False):\n",
        "        super(UNetConvBlock, self).__init__()\n",
        "        self.downsample = downsample\n",
        "        self.identity = nn.Conv2d(in_size, out_size, 1, 1, 0)\n",
        "        self.use_csff = use_csff\n",
        "\n",
        "        self.conv_1 = nn.Conv2d(in_size, out_size, kernel_size=3, padding=1, bias=True)\n",
        "        self.relu_1 = nn.LeakyReLU(relu_slope, inplace=False)\n",
        "        self.conv_2 = nn.Conv2d(out_size, out_size, kernel_size=3, padding=1, bias=True)\n",
        "        self.relu_2 = nn.LeakyReLU(relu_slope, inplace=False)\n",
        "\n",
        "        if downsample and use_csff:\n",
        "            self.csff_enc = nn.Conv2d(out_size, out_size, 3, 1, 1)\n",
        "            self.csff_dec = nn.Conv2d(out_size, out_size, 3, 1, 1)\n",
        "\n",
        "        if use_HIN:\n",
        "            self.norm = nn.InstanceNorm2d(out_size//2, affine=True)\n",
        "        self.use_HIN = use_HIN\n",
        "\n",
        "        if downsample:\n",
        "            self.downsample = conv_down(out_size, out_size, bias=False)\n",
        "\n",
        "    def forward(self, x, enc=None, dec=None):\n",
        "        out = self.conv_1(x)\n",
        "\n",
        "        if self.use_HIN:\n",
        "            out_1, out_2 = torch.chunk(out, 2, dim=1)\n",
        "            out = torch.cat([self.norm(out_1), out_2], dim=1)\n",
        "        out = self.relu_1(out)\n",
        "        out = self.relu_2(self.conv_2(out))\n",
        "\n",
        "        out += self.identity(x)\n",
        "        if enc is not None and dec is not None:\n",
        "            assert self.use_csff\n",
        "            out = out + self.csff_enc(enc) + self.csff_dec(dec)\n",
        "        if self.downsample:\n",
        "            out_down = self.downsample(out)\n",
        "            return out_down, out\n",
        "        else:\n",
        "            return out\n",
        "\n",
        "\n",
        "class UNetUpBlock(nn.Module):\n",
        "    def __init__(self, in_size, out_size, relu_slope):\n",
        "        super(UNetUpBlock, self).__init__()\n",
        "        self.up = nn.ConvTranspose2d(in_size, out_size, kernel_size=2, stride=2, bias=True)\n",
        "        self.conv_block = UNetConvBlock(in_size, out_size, False, relu_slope)\n",
        "\n",
        "    def forward(self, x, bridge):\n",
        "        up = self.up(x)\n",
        "        out = torch.cat([up, bridge], 1)\n",
        "        out = self.conv_block(out)\n",
        "        return out\n",
        "\n",
        "class Subspace(nn.Module):\n",
        "\n",
        "    def __init__(self, in_size, out_size):\n",
        "        super(Subspace, self).__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        self.blocks.append(UNetConvBlock(in_size, out_size, False, 0.2))\n",
        "        self.shortcut = nn.Conv2d(in_size, out_size, kernel_size=1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sc = self.shortcut(x)\n",
        "        for i in range(len(self.blocks)):\n",
        "            x = self.blocks[i](x)\n",
        "        return x + sc\n",
        "\n",
        "\n",
        "class skip_blocks(nn.Module):\n",
        "\n",
        "    def __init__(self, in_size, out_size, repeat_num=1):\n",
        "        super(skip_blocks, self).__init__()\n",
        "        self.blocks = nn.ModuleList()\n",
        "        self.re_num = repeat_num\n",
        "        mid_c = 128\n",
        "        self.blocks.append(UNetConvBlock(in_size, mid_c, False, 0.2))\n",
        "        for i in range(self.re_num - 2):\n",
        "            self.blocks.append(UNetConvBlock(mid_c, mid_c, False, 0.2))\n",
        "        self.blocks.append(UNetConvBlock(mid_c, out_size, False, 0.2))\n",
        "        self.shortcut = nn.Conv2d(in_size, out_size, kernel_size=1, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        sc = self.shortcut(x)\n",
        "        for m in self.blocks:\n",
        "            x = m(x)\n",
        "        return x + sc"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oPJq9JApAKP"
      },
      "source": [
        "###Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04pF0gR-fWMr"
      },
      "source": [
        "**NOTE:** The dataset section can vary between analysis!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lHR6hyVoXJnT"
      },
      "source": [
        "####Dataset class and transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LIhPd41Kzbau"
      },
      "source": [
        "# define dataset class\n",
        "\n",
        "class HDF5Dataset(data.Dataset):\n",
        "  \"\"\"Represents a HDF5 dataset. with X = 'data' and y = 'labels'\n",
        "  \n",
        "  Input params:\n",
        "      file_path: Path to the HDF5 file\n",
        "      transform: PyTorch transform to apply to every data instance (default=None).\n",
        "  \"\"\"\n",
        "  def __init__(self, config, file_loc=None, transform=True):\n",
        "    super().__init__()\n",
        "    self.transform = transform\n",
        "    self.config = config\n",
        "\n",
        "    P = Path(file_loc)\n",
        "    # Search for all h5 files in path\n",
        "    self.file = h5py.File(P, 'r')\n",
        "    # return number of samples\n",
        "    self.n_samples = len(self.file.get('data'))\n",
        "    \n",
        "    # create patches of patch_size\n",
        "    self.patch_size = config.patch_size\n",
        "    self.stride = config.patch_stride  # for even patches\n",
        "       \n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    '''\n",
        "    returns items X and y. If config\n",
        "    '''\n",
        "    X, y = self.load_file(index)  # -> [w, h, c]\n",
        "\n",
        "    if self.config.transformed_when == 'before':\n",
        "      if self.transform:\n",
        "        X, y = transform_func(X, y, self.config)\n",
        "    else:    \n",
        "      X = torch.from_numpy(np.float32(X)).permute(2, 0, 1)  # -> [c, w, h]\n",
        "      if self.config.patch_size > 0:\n",
        "        X = X.unfold(1, self.patch_size, self.stride).unfold(2, self.patch_size, self.stride).unfold(3, self.patch_size, self.stride) # -> [c, vert_patches, horiz_patches, img, height, width]\n",
        "        X = torch.flatten(X, start_dim=1, end_dim=3).permute(1, 0, 2, 3) / 255 # -> [patches, c, height, width]  0 to 1 \n",
        "\n",
        "      y = torch.from_numpy(np.float32(y)).permute(2, 0, 1)  # -> [c, w, h]\n",
        "      if self.config.patch_size > 0:\n",
        "        y = y.unfold(1, self.patch_size, self.stride).unfold(2, self.patch_size, self.stride).unfold(3, self.patch_size, self.stride) # -> [c, vert_patches, horiz_patches, img, height, width]\n",
        "        y = torch.flatten(y, start_dim=1, end_dim=3).permute(1, 0, 2, 3) / 255 # -> [patches, c, height, width]  0 to 1\n",
        "\n",
        "      num_patches = int(X.shape[0])\n",
        "\n",
        "      if self.transform:\n",
        "        for img in range(0, num_patches):\n",
        "          X_temp, y_temp = transform_func(X[img], y[img], self.config)\n",
        "          X_temp = X_temp[None, :, :]\n",
        "          y_temp = y_temp[None, :, :]\n",
        "          torch.cat((X, X_temp), 0)\n",
        "          torch.cat((y, y_temp), 0)\n",
        "    return (X, y)\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    # allows length of dataset to be returned\n",
        "    return self.n_samples\n",
        "\n",
        "\n",
        "  def load_file(self, index):\n",
        "    ''' load index of database '''\n",
        "    X = self.file.get('data')[index]\n",
        "    y = self.file.get('labels')[index]\n",
        "\n",
        "    return (X, y)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yymOH1g01_cW"
      },
      "source": [
        "class MiniBatchDataset(HDF5Dataset):\n",
        "  \"\"\"Represents a HDF5 dataset. with X = 'data' and y = 'labels'\n",
        "  \n",
        "  Input params:\n",
        "      file_path: Path to the HDF5 file\n",
        "      transform: PyTorch transform to apply to every data instance (default=None).\n",
        "  \"\"\"\n",
        "  def __init__(self, X, y, config):\n",
        "    super().__init__(config, fpath)\n",
        "    assert X.shape[0] == y.shape[0] # assuming shape[0] = dataset size\n",
        "    self.X = X\n",
        "    self.y = y\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.y.shape[0]\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.X[index], self.y[index]\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zlfZyy0GjDTS"
      },
      "source": [
        "  #transform functions\n",
        "  \n",
        "  def transform_func(image, label, config):\n",
        "\n",
        "      '''\n",
        "      Apply transforms to image and label\n",
        "      '''\n",
        "      \n",
        "      # convert to PIL image\n",
        "      image = transforms.functional.to_pil_image(image)\n",
        "      label = transforms.functional.to_pil_image(label)\n",
        "\n",
        "      if config.transform1 == \"hflip\":\n",
        "        # Random horizontal flipping\n",
        "        if random.random() > 0.5:\n",
        "            image = transforms.functional.hflip(image)\n",
        "            label = transforms.functional.hflip(label)\n",
        "\n",
        "      if config.transform1 == \"hflip\":\n",
        "        # Random 90 deg rotation\n",
        "        if random.random() > 0.5:\n",
        "            image = transforms.functional.rotate(image, 90)\n",
        "            label = transforms.functional.rotate(label, 90)\n",
        "\n",
        "      # Transform to tensor\n",
        "      image = transforms.functional.to_tensor(image)\n",
        "      label = transforms.functional.to_tensor(label)\n",
        "\n",
        "      return image, label"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ehwgeTtEnkHr"
      },
      "source": [
        "####Split dataset into train, val, test split"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVIpfN1xDJau"
      },
      "source": [
        "def train_val_test_split(dataset):\n",
        "\n",
        "  # perform random splits on dataset to return train, val, test sets (manual seed fixes output for repeatable results , remove device = cuda for non. GPU )\n",
        "  dataset_length = len(dataset)\n",
        "\n",
        "  # set sizes\n",
        "  train_set_size = 0.8\n",
        "  val_set_size = 0.1\n",
        "  test_set_size = 0.1\n",
        "\n",
        "  # return lengths\n",
        "  train_set_length = round(train_set_size * dataset_length, 0)\n",
        "  val_set_length = round(val_set_size * dataset_length, 0)\n",
        "  test_set_length = dataset_length - train_set_length - val_set_length\n",
        "\n",
        "  # check\n",
        "  total = train_set_length + val_set_length + test_set_length\n",
        "  print(f'total length: {total} / train set length: {train_set_length} / validation set length: {val_set_length} / test set length: {test_set_length}')\n",
        "  assert total == dataset_length\n",
        "\n",
        "  # create datasets\n",
        "  train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(\n",
        "      dataset,\n",
        "      [int(train_set_length), int(val_set_length), int(test_set_length)],\n",
        "      generator=torch.Generator().manual_seed(42)\n",
        "  )\n",
        "\n",
        "  return train_dataset, val_dataset, test_dataset\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cNw8LDzoXSvH"
      },
      "source": [
        "####Test plot functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vAxKNdk3gpVj"
      },
      "source": [
        "def test_plot_Xy_batch(dataset):\n",
        " \n",
        "  # plot images\n",
        "  num_cols = 4\n",
        "  num_patches = int(num_cols / 2)\n",
        "  num_rows = 2\n",
        "  fig, axs = plt.subplots(num_rows, num_cols, figsize=(16, 16), sharey=True)\n",
        "  fig.suptitle(\"Train sample example images\")\n",
        "\n",
        "  row = 0\n",
        "  for image in range(0, num_rows):  # plot two images in batch\n",
        "    X, y = dataset.__getitem__(image)\n",
        "    col = 0\n",
        "    for patch in range(0, num_patches):  #plot patches\n",
        "      X_img_patches = X.permute(0, 2, 3, 1)\n",
        "      X_img = X_img_patches[patch]\n",
        "\n",
        "      y_img_patches = y.permute(0, 2, 3, 1)\n",
        "      y_img = y_img_patches[patch]\n",
        "\n",
        "      axs[row, col].imshow(X_img)\n",
        "      axs[row, col].title.set_text(f'Batch {image} X train example patch {patch}')\n",
        "      col += 1\n",
        "      axs[row, col].imshow(y_img)\n",
        "      axs[row, col].title.set_text(f'Batch {image} y train example patch {patch}')\n",
        "      col += 1\n",
        "    row += 1"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GII5d-kId-Fz"
      },
      "source": [
        "def test_plot_Xy_train_val_test_dataset(train_dataset, val_dataset, test_dataset):\n",
        "  # Get dataset items\n",
        "  test_index = 1\n",
        "  X_train, y_train = train_dataset.__getitem__(test_index)\n",
        "  X_val, y_val = val_dataset.__getitem__(test_index)\n",
        "  X_test, y_test = test_dataset.__getitem__(test_index)\n",
        "\n",
        "  patch = 0\n",
        "  \n",
        "  # plot images\n",
        "  fig, axs = plt.subplots(3, 2, figsize=(16, 16), sharey=True)\n",
        "  fig.suptitle(\"Train, validation, test dataset sample example images\")\n",
        "  axs[0, 0].imshow(X_train.permute(0, 2, 3, 1)[patch])\n",
        "  axs[0, 0].title.set_text('X train example image')\n",
        "  axs[0, 1].imshow(y_train.permute(0, 2, 3, 1)[patch])\n",
        "  axs[0, 1].title.set_text('y train example image')\n",
        "  axs[1, 0].imshow(X_val.permute(0, 2, 3, 1)[patch])\n",
        "  axs[1, 0].title.set_text('X validation example image')\n",
        "  axs[1, 1].imshow(y_val.permute(0, 2, 3, 1)[patch])\n",
        "  axs[1, 1].title.set_text('y validation example image')\n",
        "  axs[2, 0].imshow(X_test.permute(0, 2, 3, 1)[patch])\n",
        "  axs[2, 0].title.set_text('X test example image')\n",
        "  axs[2, 1].imshow(y_test.permute(0, 2, 3, 1)[patch])\n",
        "  axs[2, 1].title.set_text('y test example image')"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJKW1rUt8bKh"
      },
      "source": [
        "###Custom Loss Function "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76lRNVcp330E"
      },
      "source": [
        "# create custom PSNRLoss class\n",
        "\n",
        "class PSNRLoss(nn.Module):\n",
        "\n",
        "  def __init__(self):\n",
        "    super(PSNRLoss, self).__init__()\n",
        "\n",
        "  def forward(self, R, X, y, data_range=1.0, reduction='mean', convert_to_greyscale=False):\n",
        "      r\"\"\"Compute Peak Signal-to-Noise Ratio for a batch of images.\n",
        "      Supports both greyscale and color images with RGB channel order.\n",
        "      Args:\n",
        "          R: An input tensor. Shape :math:`(2, N, C, H, W)`.  where position 0 is [stage1 output, stage 2 output] -> outputs from model\n",
        "          x: An input tensor. Shape :math:`(N, C, H, W)`.\n",
        "          y: A target tensor. Shape :math:`(N, C, H, W)`.\n",
        "          data_range: Maximum value range of images (usually 1.0 or 255).\n",
        "          reduction: Specifies the reduction type:\n",
        "              ``'none'`` | ``'mean'`` | ``'sum'``. Default: ``'mean'``\n",
        "          convert_to_greyscale: Convert RGB image to YCbCr format and computes PSNR\n",
        "              only on luminance channel if `True`. Compute on all 3 channels otherwise.\n",
        "      Returns:\n",
        "          PSNR Index of similarity betwen two images.\n",
        "      References:\n",
        "          https://en.wikipedia.org/wiki/Peak_signal-to-noise_ratio\n",
        "      \"\"\"\n",
        "      # Constant for numerical stability\n",
        "      EPS = 1e-8\n",
        "\n",
        "      X = X / float(data_range)\n",
        "      y = y / float(data_range)\n",
        "      R[0] = (R[0] / float(data_range)).to(device)\n",
        "      R[1] = (R[1] / float(data_range)).to(device)\n",
        "      \n",
        "\n",
        "      if (X.size(1) == 3) and convert_to_greyscale:\n",
        "          # Convert RGB image to YCbCr and take luminance: Y = 0.299 R + 0.587 G + 0.114 B\n",
        "          rgb_to_grey = torch.tensor([0.299, 0.587, 0.114]).view(1, -1, 1, 1).to(X)\n",
        "          R[0] = torch.sum(R[0] * rgb_to_grey, dim=1, keepdim=True)\n",
        "          R[1] = torch.sum(R[1] * rgb_to_grey, dim=1, keepdim=True)\n",
        "          X = torch.sum(X * rgb_to_grey, dim=1, keepdim=True)\n",
        "          y = torch.sum(y * rgb_to_grey, dim=1, keepdim=True)\n",
        "\n",
        "      score = []\n",
        "      for i in range(0, len(R)):\n",
        "        mse = torch.mean(((R[i].add(X)) - y) ** 2, dim=[1, 2, 3])\n",
        "        max_value = 1. if X[0].max() <= 1 else 255. # max pixel value\n",
        "        score.append(20. * torch.log10(max_value / torch.sqrt(mse)))\n",
        "\n",
        "      summed_loss = score[0].add(score[1])\n",
        "      summed_loss = -1. * summed_loss\n",
        "\n",
        "      return _reduced(summed_loss, reduction) # reduced to single value\n",
        "\n",
        "    \n",
        "def _reduced(loss, reduction_type):\n",
        "  r\"\"\"Reduce input in batch dimension if needed.\n",
        "  Args:\n",
        "      x: Tensor with shape (N, *).\n",
        "      reduction: Specifies the reduction type:\n",
        "          ``'none'`` | ``'mean'`` | ``'sum'``. Default: ``'mean'``\n",
        "  \"\"\"\n",
        "  if reduction_type == 'none':\n",
        "      return loss\n",
        "  elif reduction_type == 'mean':\n",
        "      return loss.mean(dim=0)\n",
        "  elif reduction_type == 'sum':\n",
        "      return loss.sum(dim=0)\n",
        "  else:\n",
        "      raise ValueError(\"Uknown reduction. Expected one of {'none', 'mean', 'sum'}\")\n",
        "\n"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8L0asjYlIyLN"
      },
      "source": [
        "###Make model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGqP3iEGlLKd"
      },
      "source": [
        "def make(config, device):\n",
        "    \n",
        "    verbose = config.verbose\n",
        "\n",
        "    # create dataset\n",
        "    file_loc = fpath\n",
        "    dataset = HDF5Dataset(config, file_loc=fpath, transform=True)\n",
        "    train_dataset, val_dataset, test_dataset = train_val_test_split(dataset)\n",
        "    \n",
        "    if verbose==1:\n",
        "      # plot dataset info\n",
        "      test_plot_Xy_batch(train_dataset)\n",
        "      test_plot_Xy_train_val_test_dataset(train_dataset, val_dataset, test_dataset)\n",
        "\n",
        "    # create dataloader\n",
        "    train_dataloader = make_loader(config, train_dataset)\n",
        "    val_dataloader = make_loader(config, val_dataset)\n",
        "    test_dataloader = make_loader(config, test_dataset)\n",
        "    # set up a dictionary of dataloaders for train and val\n",
        "    dataloader = {'train': train_dataloader, 'val': val_dataloader, 'test': test_dataloader}\n",
        "    dataset_sizes = {'train': len(train_dataloader), 'val': len(val_dataloader), 'test': len(test_dataloader)} \n",
        "    if verbose==1:\n",
        "      print(f'Dataset sizes: {dataset_sizes}')\n",
        "\n",
        "    # Make the model\n",
        "    model = HINet().to(device)\n",
        "\n",
        "    # set loss type\n",
        "    if config.loss_type == \"PSNR\":\n",
        "      criterion = PSNRLoss().to(device)  # custom loss\n",
        "    elif config.loss_type == \"MSE\":\n",
        "      criterion = MSELoss().to(device)\n",
        "\n",
        "    # set optimizer type\n",
        "    if config.optimizer_type == \"Adam\":\n",
        "      optimizer = torch.optim.Adam(model.parameters(), lr=config.initial_learning_rate)\n",
        "    elif config.optimizer_type == \"SGD\":\n",
        "      optimizer = torch.optim.SGD(model.parameters(), lr=config.initial_learning_rate)\n",
        "\n",
        "    # set learning rate scheduler \n",
        "    if config.scheduler_type == \"cosine_annealing\":\n",
        "      model_lr_scheduler = lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.max_itterations, eta_min=config.min_learning_rate, last_epoch=-1, verbose=False)\n",
        "\n",
        "\n",
        "    return model, dataloader, dataset_sizes, criterion, optimizer, model_lr_scheduler"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gaKVAT3sz16n"
      },
      "source": [
        "####Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "akfREZjZQ4Dm"
      },
      "source": [
        "def make_loader(config, dataset):\n",
        "    loader = data.DataLoader(\n",
        "        dataset=dataset,\n",
        "        batch_size=config.batch, \n",
        "        shuffle=False,\n",
        "        pin_memory=False, \n",
        "        num_workers=1\n",
        "    )\n",
        "    return loader"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8IXRPNZWdssT"
      },
      "source": [
        "###Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85bWkHvp0l81"
      },
      "source": [
        "# training loop\n",
        "\n",
        "def train_model(model, config, device, dataloader, dataset_sizes, criterion, optimizer, scheduler):\n",
        "  verbose = config.verbose\n",
        "  plot_itter = config.plot_itterations\n",
        "  num_epochs = config.num_epoch\n",
        "  mini_batch_size = config.mini_batch_size\n",
        "  # tell wandb to watch\n",
        "  wandb.watch(model, criterion, log=\"all\", log_freq=plot_itter)\n",
        "  # start timer\n",
        "  since = time.time()\n",
        "  if verbose == 1:\n",
        "    print('Total progress...')\n",
        "  #initialise variables\n",
        "  output_dict = {\n",
        "      'num_training_examples': 0\n",
        "  }\n",
        "  num_itters = 0\n",
        "  num_training_examples = 0\n",
        "  num_validation_examples = 0\n",
        "  # load existing best weights and reset accuracy\n",
        "  best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "  # begin analysis\n",
        "  for epoch in tqdm(range(num_epochs)):\n",
        "    if num_itters > max_itterations:\n",
        "      break\n",
        "    else:\n",
        "      print(f'\\nEpoch {epoch + 1} / {num_epochs}')\n",
        "      print('-' * 10)\n",
        "\n",
        "      for phase in ['train', 'val']:\n",
        "        since_phase = time.time()\n",
        "        if verbose == 1:\n",
        "          print(f'Phase -> {phase}')\n",
        "          print(f'Batches...')\n",
        "          print('-' * 10)\n",
        "        # loop train and val phase for each dataset\n",
        "        best_loss = 1e5  # large so always saves best loss\n",
        "        epoch_running_loss = 0\n",
        "        epoch_loss = 0\n",
        "        total_imgs_in_batches = 0\n",
        "        for batch_idx, (images, labels) in enumerate(tqdm(dataloader[phase])):\n",
        "          # get images and labels\n",
        "          images_batch = torch.flatten(images, start_dim=0, end_dim=1)  # -> [imgs (batch*patches), channels, height, width]\n",
        "          labels_batch = torch.flatten(labels, start_dim=0, end_dim=1)       \n",
        "          imgs_in_batch = images_batch.shape[0]\n",
        "          total_imgs_in_batches += imgs_in_batch\n",
        "\n",
        "          # create dataset for mini-batches\n",
        "          mini_batch_data = MiniBatchDataset(images_batch, labels_batch, config) \n",
        "          mini_batch_dataloader = make_loader(config, mini_batch_data) \n",
        "          if phase == 'train':\n",
        "            print(f'Mini-batches -> Total training examples = {num_training_examples}')\n",
        "\n",
        "          for mini_batch_idx, (mini_batch_images, mini_batch_labels) in enumerate(mini_batch_dataloader):\n",
        "            # get images labels and indices\n",
        "            mini_batch_images = mini_batch_images.to(device)  # -> [mb, c, h, w]\n",
        "            mini_batch_labels = mini_batch_labels.to(device)\n",
        "            imgs_in_mini_batch = mini_batch_images.shape[0]\n",
        "\n",
        "            if phase == 'train':  # TRAINING\n",
        "              model.train().to(device)  # set to training mode\n",
        "              # FORWARD PASS\n",
        "              with torch.set_grad_enabled(True):\n",
        "                outputs = model(mini_batch_images) # -> [mini_batch, channels, height, width] -> outputs is [out_1 (STAGE 1 output image), out_2 (STAGE 2 output image)]\n",
        "                loss = criterion(outputs, mini_batch_images, mini_batch_labels, data_range=1.0, reduction='mean').to(device)\n",
        "                num_training_examples += mini_batch_images.shape[0]\n",
        "                epoch_running_loss += (loss.item() * imgs_in_mini_batch)  # mult by batch to allow avg (epoch loss) to be calcd.\n",
        "                # BACKWARD PASS\n",
        "                optimizer.zero_grad()  # emptys cache\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "                num_itters += 1\n",
        "\n",
        "\n",
        "            else:  # VALIDATION\n",
        "              model.eval()  # set to training mode\n",
        "              # FORWARD PASS\n",
        "              with torch.set_grad_enabled(False):\n",
        "                outputs = model(mini_batch_images) # -> [mini_batch, channels, height, width] -> outputs is [out_1 (STAGE 1 output image), out_2 (STAGE 2 output image)]\n",
        "                loss = criterion(outputs, mini_batch_images, mini_batch_labels, data_range=1.0, reduction='mean').to(device)\n",
        "                num_validation_examples += mini_batch_images.shape[0]\n",
        "                epoch_running_loss += (loss.item() * imgs_in_mini_batch)\n",
        "                num_itters += 1\n",
        "          \n",
        "          if [plot_itter==1 and batch_idx==0 and mini_batch_idx==0 and phase=='val'] or [epoch+1%plot_itter==0 and batch_idx==0 and mini_batch_idx==0 and phase=='val']:  # every Xth val epoch save data from 0th batch and 0th minibatch for plotting\n",
        "            wandb.log({\n",
        "                \"epoch\": epoch + 1,\n",
        "                \"input image\": [wandb.Image(mini_batch_images[0].permute(1, 2, 0).to('cpu').numpy(), caption=\"Input image\")],\n",
        "                \"ground truth image\": [wandb.Image(mini_batch_labels[0].permute(1, 2, 0).to('cpu').numpy(), caption=\"Ground truth image\")],\n",
        "                \"Output image stage 1\": [wandb.Image(outputs[0][0].permute(1, 2, 0).to('cpu').detach().numpy(), caption=\"Output image stage 1\")],\n",
        "                \"Output image stage 2\": [wandb.Image(outputs[1][0].permute(1, 2, 0).to('cpu').detach().numpy(), caption=\"Output image stage 2\")]\n",
        "                },\n",
        "                step=num_training_examples,\n",
        "                commit=False\n",
        "            )\n",
        "        \n",
        "        # print phase time\n",
        "        phase_time = time.time() - since_phase \n",
        "        print(f'Epoch {epoch+1} {phase} time: {phase_time // 60:.0f}m {phase_time % 60:.0f}s')\n",
        "        \n",
        "        # log epoch loss\n",
        "        epoch_loss = epoch_running_loss / total_imgs_in_batches # average of epoch losses\n",
        "        print(f'epoch {epoch+1} {phase} loss: {epoch_loss}')\n",
        "        if epoch % plot_itter == 0 or plot_itter==1:  # every Xth epoch save data for plotting\n",
        "            wandb.log({f\"epoch {phase} loss\": epoch_loss}, step=num_training_examples)\n",
        "\n",
        "        # deep copy the model if best loss\n",
        "        if phase == 'val' and epoch_loss < best_loss: \n",
        "          best_loss = epoch_loss\n",
        "          best_loss_epoch = epoch\n",
        "          best_model_wts = copy.deepcopy(model.state_dict())\n",
        "        del loss, outputs\n",
        "\n",
        "    # print time for epoch\n",
        "    epoch_time = time.time() - since\n",
        "    print(f'Epoch best validation loss: {best_loss:.4f} @ epoch {best_loss_epoch+1}')\n",
        "    print(f'Epoch {epoch+1} time: {epoch_time // 60:.0f}m {epoch_time % 60:.0f}s')\n",
        "\n",
        "  # print total training time over all epochs\n",
        "  total_time = time.time() - since\n",
        "  print(f'Total time for training {num_epochs} epochs: {total_time // 60:.0f}m {total_time % 60:.0f}s')\n",
        "  output_dict['num_training_examples'] = num_training_examples\n",
        "\n",
        "  return output_dict"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmeWK6FRJin4"
      },
      "source": [
        "####Training loop image plotting check function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FNgwb6oTLLUK"
      },
      "source": [
        "# # write function to plot figure of input v output to tensorboard\n",
        "# def plot_output_comparison(output_dict, batch_size):\n",
        "#     '''\n",
        "#     Generates matplotlib Figure using a trained network, along with images\n",
        "#     from a batch\n",
        "#     '''\n",
        "#     # output list shape -> [(epoch, item, batch)]\n",
        "#     columns = ['noisy', 'ground truth']\n",
        " \n",
        "#     # append epochs to noisy and ground truth list - e.g. noisy, ground truth, epoch 1, epoch 2, ...\n",
        "#     [columns.append(f'Epoch {epoch+1}') for epoch in output_dict['epoch']]\n",
        " \n",
        "#     # plot the images from X input (noisy), y output (GT) and acorss the epochs for the entire batch\n",
        "#     fig, axs = plt.subplots(batch, len(columns), figsize=(16, 16), sharey=True)\n",
        "#     fig.suptitle(\"Model Output\")\n",
        "#     for i in range(0, batch):  # rows\n",
        "#       epoch_number = 0 \n",
        "#       for j in range(0, len(columns)):  # columns\n",
        "#         if i == 0:\n",
        "#           # create column labels\n",
        "#           axs[i, j].set_title(f'{columns[j]}')\n",
        "#         if j == 0:\n",
        "#           # create row labels\n",
        "#           axs[i, j].set_ylabel(f'Image\\nbatch\\n{i+1}', rotation=0, size='large', labelpad=50)\n",
        " \n",
        "#         # plot all epochs of image batch set\n",
        "#         if j == 0:\n",
        "#           X_img = normalize_output(output_dict['images'][0][i]) # -> [dictionary][image types][batch]\n",
        "#           axs[i, j].imshow(X_img.permute(1, 2, 0).detach().numpy())  \n",
        "#           axs[i, j].set_xticks([])\n",
        "#           axs[i, j].set_yticks([])\n",
        "#         elif j == 1:\n",
        "#           y_img = normalize_output(output_dict['labels'][0][i])\n",
        "#           axs[i, j].imshow(y_img.permute(1, 2, 0).detach().numpy())\n",
        "#           axs[i, j].set_xticks([])\n",
        "#           axs[i, j].set_yticks([])\n",
        "#         else:\n",
        "#           output_img = normalize_output(output_dict['outputs'][j-2][1])\n",
        "#           print(f'outputimg shape: output_img.shape')\n",
        "#           axs[i, j].imshow( output_img.permute(1, 2, 0).detach().numpy())\n",
        "#           axs[i, j].set_xticks([])\n",
        "#           axs[i, j].set_yticks([])\n",
        "#           epoch_number += 1\n",
        " \n",
        "#     fig.subplots_adjust(hspace=0, wspace=0)\n",
        "\n",
        " \n",
        "#     return fig"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yaur8LWUHPya"
      },
      "source": [
        "def normalize_output(img):\n",
        "    img = img - img.min()\n",
        "    img = img / img.max()\n",
        "    return img"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rIQvfNO3JmT-"
      },
      "source": [
        "###Test Function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nHiALgWUnrUT"
      },
      "source": [
        "def test(model, config, device, criterion, dataloader, dataset_sizes, num_training_examples):\n",
        "  with torch.no_grad(): # stops computation of grads\n",
        "    running_loss = 0\n",
        "    total_imgs = 0\n",
        "    num_test_examples = 0\n",
        "    for batch_idx, (images, labels) in enumerate(tqdm(dataloader['test'])):\n",
        "      # get images and labels\n",
        "      images_batch = torch.flatten(images, start_dim=0, end_dim=1)  # -> [imgs (batch*patches), channels, height, width]\n",
        "      labels_batch = torch.flatten(labels, start_dim=0, end_dim=1)       \n",
        "      imgs_in_batch = images_batch.shape[0]\n",
        "      total_imgs += imgs_in_batch\n",
        "\n",
        "      # create dataset for mini-batches\n",
        "      mini_batch_data = MiniBatchDataset(images_batch, labels_batch, config) \n",
        "      mini_batch_dataloader = make_loader(config, mini_batch_data) \n",
        "      print(f'Mini-batches -> Testing after {num_training_examples} -> Test examples = {num_test_examples}')\n",
        "      for mini_batch_idx, (mini_batch_images, mini_batch_labels) in enumerate(mini_batch_dataloader):\n",
        "        # get images labels and indices\n",
        "        mini_batch_images = mini_batch_images.to(device)  # -> [mb, c, h, w]\n",
        "        mini_batch_labels = mini_batch_labels.to(device)\n",
        "        mini_batch_size = mini_batch_images.shape[0]\n",
        "\n",
        "        outputs = model(mini_batch_images) # -> [mini_batch, channels, height, width] -> outputs is [out_1 (STAGE 1 output image), out_2 (STAGE 2 output image)]\n",
        "        output_stage1 = outputs[0].to(device)\n",
        "        output_stage2 = outputs[1].to(device)\n",
        "        # determine losses    \n",
        "        loss = criterion(outputs, mini_batch_images, mini_batch_labels, data_range=1.0, reduction='mean').to(device)\n",
        "        num_test_examples += mini_batch_images.shape[0]\n",
        "        running_loss += loss.item() * mini_batch_size  # mult by batch to allow avg (epoch loss) to be calcd.\n",
        "      \n",
        "\n",
        "    total_loss = running_loss / total_imgs\n",
        "    wandb.log({\"Test loss\": total_loss}, step=num_training_examples)\n",
        "    print(f'\\nTest loss of the network: {loss}')"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3VwPW9_3JvNH"
      },
      "source": [
        "###Model pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTby5tpBGHqE"
      },
      "source": [
        "#Model Pipeline - train, val, test\n",
        "\n",
        "def model_pipeline(hyperparameters):\n",
        "    \n",
        "    verbose = hyperparameters['verbose']\n",
        "\n",
        "    # run on device\n",
        "    if torch.cuda.is_available():\n",
        "      device = 'cuda'\n",
        "    else:\n",
        "      device = 'cpu'\n",
        "\n",
        "    # tell wandb to get started\n",
        "    with wandb.init(project=project_name, config=hyperparameters):\n",
        "      # access all HPs through wandb.config, so logging matches execution!\n",
        "      config = wandb.config\n",
        "      \n",
        "      # make the model, data, and optimization problem\n",
        "      model, dataloader, dataset_sizes, criterion, optimizer, model_lr_scheduler = make(config, device)\n",
        "      print(model)\n",
        "\n",
        "      # perform training and evaluating\n",
        "      output_dict = train_model(model, config, device, dataloader, dataset_sizes, criterion, optimizer, model_lr_scheduler)\n",
        "\n",
        "      # Test final performance\n",
        "      test(model, config, device, criterion, dataloader, dataset_sizes, output_dict['num_training_examples'])\n",
        "\n",
        "    return model"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4cWiKtrGgetG"
      },
      "source": [
        "#RUN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KuvrXcY-J00L"
      },
      "source": [
        "##Train, Validate, test!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y_TU0rKwJzvm",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "ac7ff71826e340e3bad33ba4276d6c71",
            "5a2568aefb9a47e5a3b631d53254b85e",
            "ea916194a6ec474e9843c973126e9127",
            "26608bdcbf9a445c8f0c7d250a87c827",
            "717d805684e4431fba435aba5744883c",
            "03ed9f7cea9a4aa38cdfd7e28b4f8535",
            "028d1bd0478049b7b67f3101cc5dda3d",
            "cfb74b1388ee4b17989c7c19f3df9054",
            "9b042f5a74b24a1399fb9fe51cdb2721",
            "78882d6a148a4d50b0bbca8f5483b4c6",
            "fb1038999bfb46bdb1688a7aa1931b10",
            "ee3fd3b9197643ebbb3ba80821d1a969",
            "5ab3eae616a4432d9c3d256fb95b4114",
            "abcd894f10844a2e9c4912daaf87d10e",
            "1b0c934cde694723a6a55b5d6243ad59",
            "ec808e7566154ef1986bd4322639b5de",
            "3d694af831974521bb5e1a6b3009e5b6",
            "9f4890e538a04a2b91971f6d2c8c4643",
            "dffff040b01e4345a0cd96c0956c3721",
            "b7262cddab9c4dc4b4d8a1c23135f8f3",
            "f259b8261e914d7eab37239aa26393c2",
            "1876d6137793414abc93ce6133193000",
            "88286ff290e240b2ae0c3e7f0f09bdb2",
            "f6a60537223f49c28f519d805c976d82",
            "c68df2fbe94b4a459e51795104373853",
            "685a1360820d4d3caafcad7d5f27e1b1",
            "c9687f3e7f4c4385a3cdb36f4ddb222a",
            "d291d298a369495985215bea2b1c814c",
            "1c25879b45024aee946f50f9ebb32060",
            "6ee72ae0481d48b9ae704ed79a98c0e2",
            "7446320cb6084451b8ca37dea834fef5",
            "dc3f930b5cc0462eb5546bf057a487ae",
            "2473f3607714410eb29c5d6a7ea97e40",
            "ee5725f6f0424bd3b37a726ce4c9c4b6",
            "372048ff681b4ad78de7164109edfce6",
            "80a345217cce4f9ea0ca33fbd4396675",
            "4930b9a170ed44d98b7fca79f8c90e3c",
            "2e1123d569564cb3a4dd8df5d063bfb6",
            "485f368e07944635aca1e4c71ac84820",
            "582a09011a1a44f0919c3f7dea4aa48a",
            "54c441220449465b9f4315b1544e2531",
            "19bc31f2ad6a4d1497ff67bec5e1ddee",
            "0b2388ad49ad405b94c5447dce695042",
            "d338e7386285454b993cb2640d2017b2",
            "ccd9d724f41140cbacb93b36f598093d",
            "201277330fad40fbb02552308eb7b30f",
            "9f9a025f52864201ab439d8d0e6ad622",
            "d862ff7989f447d39d63090e4a1c2584",
            "5fef4567c5634bfabca3e627e21e8bba",
            "0ec357ee46614714b47f116fcf7f1a72",
            "d93a512307ce491ca857e6b73dc57c2a",
            "cf96689cb9fe4f8eb7ede80246108e49",
            "73620cc654d241d9adb0d24948c5ae8d",
            "020b410d16ab4478ad4bb659dcdc4afc",
            "149bde90a5db4c868e30a51f6fc91939",
            "dee27a23d88a481e85151969d0009cc8",
            "ac8568ac7bf040d1ac938674c7c588fb",
            "4306301c9b874fe7ab6c6fe0dae31c90",
            "3f2dc8fe70f34539be3d3125fd4026dd",
            "7d5cab5d05a6472a9771623149fafb7c",
            "7b70ca1aae3848e0899f445bc6bf14ca",
            "73aaeff9c09c48a185f581de35e5f18a",
            "45b6f69e3ab24ab7878d7b4cd34512fb",
            "5f4d91546879432c8e3d5074415a013b",
            "b675fe8e926d4744a4b98142b7b313a8",
            "2f3894c303e64f8f8721761526f25b60"
          ]
        },
        "outputId": "01fa4f2a-27c0-4109-e637-d1a14f56c477"
      },
      "source": [
        "model = model_pipeline(hyperparameters)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/amackerel/Tracker-PreProcessing-Denoising/runs/10r4iuqr\" target=\"_blank\">snowy-blaze-280</a></strong> to <a href=\"https://wandb.ai/amackerel/Tracker-PreProcessing-Denoising\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "total length: 160.0 / train set length: 128.0 / validation set length: 16.0 / test set length: 16.0\n",
            "Dataset sizes: {'train': 16, 'val': 2, 'test': 2}\n",
            "HINet(\n",
            "  (down_path_1): ModuleList(\n",
            "    (0): UNetConvBlock(\n",
            "      (identity): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (1): UNetConvBlock(\n",
            "      (identity): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (2): UNetConvBlock(\n",
            "      (identity): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): UNetConvBlock(\n",
            "      (identity): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (4): UNetConvBlock(\n",
            "      (identity): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            "  (down_path_2): ModuleList(\n",
            "    (0): UNetConvBlock(\n",
            "      (identity): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (csff_enc): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (csff_dec): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (1): UNetConvBlock(\n",
            "      (identity): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (csff_enc): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (csff_dec): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(128, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (2): UNetConvBlock(\n",
            "      (identity): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (csff_enc): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (csff_dec): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(256, 256, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (3): UNetConvBlock(\n",
            "      (identity): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (csff_enc): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (csff_dec): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (norm): InstanceNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "      (downsample): Conv2d(512, 512, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "    )\n",
            "    (4): UNetConvBlock(\n",
            "      (identity): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1))\n",
            "      (conv_1): Conv2d(512, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "      (conv_2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "      (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      (norm): InstanceNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=False)\n",
            "    )\n",
            "  )\n",
            "  (conv_01): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv_02): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (up_path_1): ModuleList(\n",
            "    (0): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (1): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (2): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (3): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (up_path_2): ModuleList(\n",
            "    (0): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(1024, 512, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (1): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (2): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "    (3): UNetUpBlock(\n",
            "      (up): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
            "      (conv_block): UNetConvBlock(\n",
            "        (identity): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "        (conv_1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_1): LeakyReLU(negative_slope=0.2)\n",
            "        (conv_2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "        (relu_2): LeakyReLU(negative_slope=0.2)\n",
            "      )\n",
            "    )\n",
            "  )\n",
            "  (skip_conv_1): ModuleList(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (skip_conv_2): ModuleList(\n",
            "    (0): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (sam12): SAM(\n",
            "    (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv2): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "    (conv3): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  )\n",
            "  (cat12): Conv2d(128, 64, kernel_size=(1, 1), stride=(1, 1))\n",
            "  (last): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            ")\n",
            "Total progress...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ac7ff71826e340e3bad33ba4276d6c71",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 / 5\n",
            "----------\n",
            "Phase -> train\n",
            "Batches...\n",
            "----------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee3fd3b9197643ebbb3ba80821d1a969",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batches -> Total training examples = 0\n",
            "Mini-batches -> Total training examples = 16\n",
            "Mini-batches -> Total training examples = 32\n",
            "Mini-batches -> Total training examples = 48\n",
            "Mini-batches -> Total training examples = 64\n",
            "Mini-batches -> Total training examples = 80\n",
            "Mini-batches -> Total training examples = 96\n",
            "Mini-batches -> Total training examples = 112\n",
            "Mini-batches -> Total training examples = 128\n",
            "Mini-batches -> Total training examples = 144\n",
            "Mini-batches -> Total training examples = 160\n",
            "Mini-batches -> Total training examples = 176\n",
            "Mini-batches -> Total training examples = 192\n",
            "Mini-batches -> Total training examples = 208\n",
            "Mini-batches -> Total training examples = 224\n",
            "Mini-batches -> Total training examples = 240\n",
            "Epoch 1 train time: 4m 31s\n",
            "Phase -> val\n",
            "Batches...\n",
            "----------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "88286ff290e240b2ae0c3e7f0f09bdb2",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batches -> Total training examples = 256\n",
            "Mini-batches -> Total training examples = 256\n",
            "Epoch 1 val time: 0m 36s\n",
            "Epoch 1 time: 5m 6s\n",
            "Epoch validation loss: -50.1294 @ epoch 1\n",
            "\n",
            "Epoch 2 / 5\n",
            "----------\n",
            "Phase -> train\n",
            "Batches...\n",
            "----------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee5725f6f0424bd3b37a726ce4c9c4b6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batches -> Total training examples = 256\n",
            "Mini-batches -> Total training examples = 272\n",
            "Mini-batches -> Total training examples = 288\n",
            "Mini-batches -> Total training examples = 304\n",
            "Mini-batches -> Total training examples = 320\n",
            "Mini-batches -> Total training examples = 336\n",
            "Mini-batches -> Total training examples = 352\n",
            "Mini-batches -> Total training examples = 368\n",
            "Mini-batches -> Total training examples = 384\n",
            "Mini-batches -> Total training examples = 400\n",
            "Mini-batches -> Total training examples = 416\n",
            "Mini-batches -> Total training examples = 432\n",
            "Mini-batches -> Total training examples = 448\n",
            "Mini-batches -> Total training examples = 464\n",
            "Mini-batches -> Total training examples = 480\n",
            "Mini-batches -> Total training examples = 496\n",
            "Epoch 2 train time: 3m 52s\n",
            "Phase -> val\n",
            "Batches...\n",
            "----------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ccd9d724f41140cbacb93b36f598093d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batches -> Total training examples = 512\n",
            "Mini-batches -> Total training examples = 512\n",
            "Epoch 2 val time: 0m 34s\n",
            "Epoch 2 time: 9m 33s\n",
            "Epoch validation loss: -55.1020 @ epoch 2\n",
            "\n",
            "Epoch 3 / 5\n",
            "----------\n",
            "Phase -> train\n",
            "Batches...\n",
            "----------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dee27a23d88a481e85151969d0009cc8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/16 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mini-batches -> Total training examples = 512\n",
            "Mini-batches -> Total training examples = 528\n",
            "Mini-batches -> Total training examples = 544\n",
            "Mini-batches -> Total training examples = 560\n",
            "Mini-batches -> Total training examples = 576\n",
            "Mini-batches -> Total training examples = 592\n",
            "Mini-batches -> Total training examples = 608\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRpkQ1VMpXoH"
      },
      "source": [
        "##Save model weights and bias"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-pxmCY4kpaHd"
      },
      "source": [
        "# save model state dict\n",
        "PATH = f'/content/gdrive/MyDrive/Programming/models/{project_name}.pth'\n",
        "torch.save(model.state_dict(), PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GIped6zW7XD9"
      },
      "source": [
        "#INFERENCE\n",
        "\n",
        "Run inference using already trained weights\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gaA48NGQ7aBr"
      },
      "source": [
        "# load model weights\n",
        "model.load_state_dict(torch.load(PATH))\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}